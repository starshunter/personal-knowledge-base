- # Midnight
- DONE commit journal
- [[Fight Song/EP5]]
	- turns out female lead wasn't fine at all
	- male lead begged CEO for another second chance, and eventually got it
	- female lead's friends take her out for camping
	- male lead went to see her, and asked to restart their relationship
- 04:45 #[[Bed Time]]
- # Morning
- 09:50 #[[Wake Time]]
- [[LeetCode Daily Challenge/2022-02]] #[[Hash Table]] #[[Two Pointers]] #String #[[Sliding Window]]
	- problem:: Permutation in String
	  link:: https://leetcode.com/problems/permutation-in-string/
	  difficulty:: Medium
	  duration:: 20 mins
	- first time solving this problem
	- use two hash tables, one for character appearance, another for times of appearance
	- should be able to reduce to one hash table
- [[The Go Workshop/Concurrent Work]] #Golang/Concurrent #Concurrent
	- concurrency means executing multiple tasks on a processor in turns, and parallelism means executing multiple tasks on multiple processor at the same time
	- goroutine
		- goroutines don't share memory like threads in OS
		- all goroutines terminate once `main()` finish execution
		- use `WaitGroup` to wait for every goroutine to finish its execution before returning `main()`
			- `wg := &sync.WaitGroup{}`
			- use `wg.Add()` to add the number of goroutine
			- use `wg.Done()` inside the goroutine to inform `WaitGroup` that a goroutine is finished
	- solving race condition
		- we need to make sure race condition won't occur on shared resources
		- atomic operation
			- `sync/atomic` package offers some functions with atomic operation
		- mutex
			- use `sync.Mutex` to create a mutex
			- use `mtx.Lock()` and `mtx.Unlock()` to protect critical section
			-
	- channel
		- create a channel using `make(chan <type>, <buffer size>)`
		- use `<channel> <- <value>` to put value into channel, and use `<variable> = <- <channel>` to take value out of channel
		- we can close a channel using `close(<channel>)`
		- there needs to be another goroutine to fetch value from the channel if a goroutine is passing a value into a channel with no buffer
	- flow control of concurrent execution
		- channel operations are blocking, if one goroutine is doing I/O on a channel, other goroutines have to wait for it
		- read/write operations on a channel will block if it exceed the buffer size
		- use `range` to read from channel allows us to read the channel continuously
			- `for i := range <channel>`
			- this will be terminated if the channel is closed and there is no value left in the channel
		- select statement
			- work just like switch statement
			- ```golang
			  select {
			  case msg1 := <- c1:
			  	<code>
			  case msg2 := <- c2:
			  	<code>
			  case msg3 := <- c3:
			  	<code>
			  case <- done:
			  	<code>
			  default:
			  	<code>
			  }
			  ```
			- a channel will become readable once it is closed
	- `context` package
		- context is a struct, it is used to send signal to goroutine to stop their execution
- # Afternoon
- # Night
- ![ch09.pdf](../assets/ch09_1644580090793_0.pdf)
	- type:: pdf
	  tags:: [[Operating System/Basic]], [[Learning/Work]], [[Job Interview]]
	  title:: Chapter 9: Virtual Memory Management
	- a program may not need to be entirely loaded into memory
		- like error handling functions
	- virtual memory is a technique that allows the execution of processes that are not completely in memory
		- logical address space can be larger than physical address space
		- virtual address space
			- how a process is logically stored in memory
			- ((62066349-47cb-4ce4-ae19-6ef84a31195e))
			- system libraries can be shared by several processes
			- enable process to share memory
			- speeding up process creation
	- demand paging
		- a technique used in virtual memory systems
		- pages are loaded only when they are demanded
		- we you lazy swapper to swap a process into memory
			- lazy swapper will not swap in pages that are not needed
		- valid-invalid bit scheme can help OS to distinguish which page is in memory, and which is on the disk
		- when accessing a page that is not in the memory, a page fault occurs
			- ((6206663e-b3b7-4b58-b922-603d8dc64951))
				- OS check internal table in PCB for a page
				- if the page is invalid, terminate the process
				- if it's valid but not in memory, OS needs to swap it in
				- use frame table to allocate a free frame
				- swap the page from disk onto the allocated frame
				- modify page table and internal table
				- restart the instruction that was interrupted
			- if page fault occurs when we fetch the operand, we may refetch the instruction
		- pure demand paging scheme
			- execute a process with no page in memory initially
	- copy-on-write
		- `fork()` will create a child process, which copy the entire parent process's address space
		- copy-on-write is a technique that allows the parent and child processes initially to share the same page
		- if a process try to modify a shared page, then a copy of that page will be created
	- page replacement
		- with virtual memory, we can over allocate memory
		- but we need to do page replacement if there is no free frame for a page to swap onto
		- ((62067f16-f84c-463e-bea9-0f1ffd5daa9a))
		- to avoid double page transfer, we can add a modify bit to page table
			- if the modify bit is set, it means that page has been modified, so it's necessary to write it back to the disk, otherwise we can just write over that page
		- FIFO
			- the oldest page is chosen when page replacement is needed
			- performance is not good
		- optimal
			- replace the page that will not be used for the longest time
			- results in the lowest page fault rate
			- impossible to implement
		- LRU
			- chooses the page that has not been used for the longest time
			- counter approach
				- use additional field to store timestamp
			- stack approach
				- after referencing a page, it will be removed from stack and added to the top
				- implement with double linked list
		- LRU-approximation
			- LRU method needs hardware support
			- each entry of page table has a reference bit
			- reference bit is set whenever that page is referenced
			- additional reference bits algorithm
				- we keep a 8 bit reference bit sequence for each page
				- for each interval, OS shifts the sequence to the left
				- if we view this sequence as unsigned integer, then we can use this integer to represent how often this page is used
				- the page with the lowest number is replaced
			- second chance algorithm
				- use FIFO
				- but check the reference bit before replacement, if the reference bit is set, we give it another chance and reset its reference bit
			- enhanced second chance algorithm
				- add modify bit
		- counting-based
			- least frequently used algorithm
			- most frequent used algorithm
	- page buffering algorithm
		- OS keeps a pool of free frames
		- we don't need to wait for a victim page to swap out to restart the process, we can just write the page into a frame inside the pool
		- and after the victim is written out, we can add its frame to the pool
		- or maintain a list of modified pages
		- write those pages to disk when the paging device is idle
	- allocation of frames
		- we must decide how many frames to allocate to each process
		- equal allocation scheme
			- split frames equally
		- proportional allocation scheme
			- allocate frames according to process size
		- the allocation may vary according to multiprogramming level
		- global replacement
			- victim frame can be the frame allocates to other process
			- results in better performance
		- local replaecment
			- victim frame can only be the frame that allocates to itself
			- frames allocation won't change
	- thrashing
		- a process is spending more time paging than executing
		- if OS is busing doing paging, CPU usage will drop, which result in more process get brought into memory
		- ((62069536-14c1-47d9-8181-007bbc566e62))
		- we must provide enough frames to process to avoid thrashing
		- locality
			- a set of pages that are actively used together
			- process moves from locality to locality
		- working-set model
			- tries to identify how many frames a process is actually using
			- ((62069634-f3db-4224-a89d-28668a2f323a))
				- if the size of current working-set exceeds allocated frames, a process need to be terminated
		- page-fault frequency
			- set upper bound and lower bound on page fault rate
			- add a process or terminate one if we reach one of these bounds
			- ((620696eb-938b-4ab3-859c-eb824fd044aa))
		-
	- memory-mapped files
		- a mechanism that allows a part of the virtual address space to be logically associated with a file
		- I/O operation of the file can be done in memory speed
		- the memory-mapped data need to be written back to disk when the file is closed
		- multiple processes may be allowed to map the same file concurrently