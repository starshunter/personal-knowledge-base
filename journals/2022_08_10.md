- # Agenda
	- #+BEGIN_QUERY
	  {:title [:h2 "Scheduled"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	            (or
	              [?block :block/scheduled ?d])
	            [(>= ?d ?start)]
	            [(<= ?d ?next)]]
	  :inputs [:7d-before :today]
	    :collapsed? false}
	  #+END_QUERY
	- #+BEGIN_QUERY
	  {:title [:h2 "Deadline"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/deadline ?d]
	            [(>= ?d ?start)]
	            [(<= ?d ?next)]]
	    :inputs [:7d-before :today]
	    :collapsed? false}
	  #+END_QUERY
# Daily Metrics
	- DONE commit journal
	  :LOGBOOK:
	  CLOCK: [2022-08-10 Wed 03:01:02]--[2022-08-10 Wed 03:01:04] =>  00:00:02
	  :END:
	- DONE workout
	- DONE LeetCode Daily Problem
	  :LOGBOOK:
	  CLOCK: [2022-08-10 Wed 08:38:53]--[2022-08-10 Wed 08:44:01] =>  00:05:08
	  :END:
# Daily Log
	- ## Midnight
		- 02:40 #[[Bed Time]]
	- ## Morning
		- 08:17 #[[Wake Time]]
		- gather notes for [[PI/Standup]]
			- for Sherlock, yesterday I was writing the two level crawling script to produce adult monitoring report, and I finished it this morning, and I'm using a single domain to test its correctness, so if it goes well, I will start to use it to process the input data and then compare the result
		- [[PI/Standup]]
	- ## Afternoon
		- need to add my user to `k8s-developer` role to create pvc #Sherlock #Omega
			- also need to add policy that allows the role to create pvc
		- prepared for tomorrow's meeting with [[MIT]] #Sherlock/Meeting
		  id:: 62f44323-85ec-4a44-a4a9-c138d02fce65
			- so I mentioned last time that in the input data there are 400 unique domains, and about 50 of these domains are not accessible by HLFS, so for these inaccessible domains, they will be displayed on the page too, and instead of showing how many unique domain, it will show domain not accessible in this column
			- and another thing similar to this but I didn't mention last time is not only domain may be inaccessible, images could also be inaccessible too, and because they are inaccessible, so the program cannot determine whether they are adult images or not, so for domains that contain inaccessible images, it will be marked images not accessible, and to see the exact images, I put them inside the pop up window, and you can check the actual image by clicking on the link, and then change the image status base on your judgement, and the effect of this action is persistent, so next time Sherlock find this image again, if will classify the image base on your decision, so you won't need to review the same images every month
			- so HLFS doesn't have built in option to crawl one level down the domain, but I can get similar result by combining its two feature, so I found HLFS can tell me every links on a page, so I use this feature to get all the links from the page provided in the input data, then send those links to HLFS again to ask it to crawl every images on those pages, so basically this will be a process with two steps, first getting links from the root, this is like augmenting the input data, so instead of one page, now we have many links that could take us to other pages, and the second phase will be actually crawling the images from the page, because in the first step we only get the url, and we need a separated request for every url to actually get the images, so this is the process I'm testing now, and by using this two level crawling method, the program can get 80 thousand images from the same input data, and compare to 3400 images by using one level crawling, that's a great improvement
			- the downside of this method is that because it only crawl one level down, so the effeteness will largely depend on the structure of the website, because it basically decide how much content the program can reach, and another thing is, comparing to having these specific page urls inside the input data, because I have to use HLFS to get the link first, so this will add another layer of complexity to the program, and it will take more time to find which step goes wrong in the future
			- I want to confirm the size and the format of the input data, so currently there are 3000 rows in the input data, will this be the size of the monthly data in the future, or will there be more, and about the format, are the names for each column fixed, because I need to extract information from the input for my script, so the column names have to be fixed
			- I already ran the script for testing and the script indeed found some adult images, but I think some images marked as nsfw are false positive, so basically after sending an image to SMP, it will return a score for that image, along with a threshold, so SMP suggests that if the score exceed that threshold, the image should be consider not safe for work, and I'm currently using this suggested threshold in my script, but I think some images are misclassified, so I'm thinking can you provide a set of images that MIT considered them as not safe for work, so I can observe the score of those images to get a better threshold, or maybe you can review the images in this spread sheet and mark you decision, so I can choose a better threshold for my script
	- ## Night
		- gathered images marked as NSFW for tomorrow's meeting #Sherlock/Meeting
		- [[騎上獨角獸/EP6]]
			- kou was disappointed about sana not giving him a response
			- sana and kotori met with haneda
			- she said a company wanted to invested 300 millions to dream pony
			- sana sister told her their mother was fired
			- a company wanted to hire kou
			- sana's mother didn't want to take money from her
			- sana ate dinner with kou
			- he told her he refused the job offer
			- dream pony invited its employees' family to the company
			- kotori invited sana's mother to the office
			- he told her he had met sana before
			- sana's mother wanted sana to help her find a new job
			- dream pony's patent was applied by another company
# Upcoming
	- #+BEGIN_QUERY
	  {:title [:h2 "Scheduled"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/scheduled ?d]
	            [(> ?d ?start)]
	            [(< ?d ?next)]]
	  :result-transform (fn [result]
	                          (sort-by (fn [d]
	                                     (get d :block/scheduled) ) result))    
	  :inputs [:today :7d-after]
	    :collapsed? false}
	  #+END_QUERY
	- #+BEGIN_QUERY
	  {:title [:h2 "Deadline"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/deadline ?d]
	            [(> ?d ?start)]
	            [(< ?d ?next)]]
	  :result-transform (fn [result]
	                          (sort-by (fn [d]
	                                     (get d :block/deadline) ) result))    
	  :inputs [:today :7d-after]
	    :collapsed? false}
	  #+END_QUERY
# Someday
	- query-table:: false
	  #+BEGIN_QUERY
	  {:title [:h2 "Tasks"]
	   :query [:find (pull ?b [* {:block/_parent ...}])
	          :where
	          [?b :block/marker ?marker]
	          (not [?b :block/scheduled ?d])
	          (not [?b :block/deadline ?d])
	  (not (page-ref ?b "templates"))
	          [(contains? #{"TODO" "DOING"} ?marker)]]
	  }
	  #+END_QUERY