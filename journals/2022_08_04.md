- # Agenda
	- #+BEGIN_QUERY
	  {:title [:h2 "Scheduled"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	            (or
	              [?block :block/scheduled ?d])
	            [(>= ?d ?start)]
	            [(<= ?d ?next)]]
	  :inputs [:7d-before :today]
	    :collapsed? false}
	  #+END_QUERY
	- #+BEGIN_QUERY
	  {:title [:h2 "Deadline"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/deadline ?d]
	            [(>= ?d ?start)]
	            [(<= ?d ?next)]]
	    :inputs [:7d-before :today]
	    :collapsed? false}
	  #+END_QUERY
# Daily Metrics
	- DONE commit journal
	- CANCELED workout
	- CANCELED LeetCode Daily Problem
	  :LOGBOOK:
	  CLOCK: [2022-08-04 Thu 08:24:54]
	  :END:
	- DONE Learn Daily JavaScript Question
	  :LOGBOOK:
	  CLOCK: [2022-08-04 Thu 02:18:10]--[2022-08-04 Thu 02:20:59] =>  00:02:49
	  :END:
# Daily Log
	- ## Midnight
		- 02:17 #[[Bed Time]]
	- ## Morning
		- 08:13 #[[Wake Time]]
		- gather notes for [[PI/Standup]]
			- for me, I was studying what HLFS can do in case the input data of the adult monitoring report doesn't contain all the url I need, and what I learned so far is that HLFS cannot get assets from pages that is not pointed by the provided url, so to get more images out of a domain, I must know more urls that point to the pages under this domain, and I found HLFS provides an option to get all the links on a page, so I will study if this option can be part of the solution, and also keep exploring other options at the same time
		- tested two level crawling using [[HLFS]] #Sherlock
			- first level crawling to get all the links
			- second level crawling to get all the images from the links
			- second level has to wait for the first level to finish
			- use domain url provided in input data to filter out external links
	- ## Afternoon
		- wrote another script to implement two level crawling #Sherlock
			- need to use additional files to store crawled pages and found pages
		- ran the script with five domains #Sherlock
			- found 1200 images
			- some pages are 404 not found
				- filter out invisible links
	- ## Night
		- ran the script with 5 domains #Sherlock
			- found 71 pages
			- found 199 images
			- finished in 8 minutes
		- gather notes for tomorrow's [[PI/Standup]]
			- for Sherlock, I was writing a script to test the idea of using HLFS to get all the outgoing links on a page, and by setting the right parameters, it indeed can return all the links on a page, but these links include those that link to pages that are not under the current domain, and those pages should not be considered as targets to get images from, so I'm finding a way to exclude these links from the response, and if there's no option to do that, I should implement a method myself
		- ran the script with 50 domains
			- found 1656 pages
			- HLFS crawling finished in 58 minutes
			- found 17609 images
# Upcoming
	- #+BEGIN_QUERY
	  {:title [:h2 "Scheduled"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/scheduled ?d]
	            [(> ?d ?start)]
	            [(< ?d ?next)]]
	  :result-transform (fn [result]
	                          (sort-by (fn [d]
	                                     (get d :block/scheduled) ) result))    
	  :inputs [:today :7d-after]
	    :collapsed? false}
	  #+END_QUERY
	- #+BEGIN_QUERY
	  {:title [:h2 "Deadline"]
	    :query [:find (pull ?block [* {:block/_parent ...}])
	            :in $ ?start ?next
	            :where
	              [?block :block/deadline ?d]
	            [(> ?d ?start)]
	            [(< ?d ?next)]]
	  :result-transform (fn [result]
	                          (sort-by (fn [d]
	                                     (get d :block/deadline) ) result))    
	  :inputs [:today :7d-after]
	    :collapsed? false}
	  #+END_QUERY
# Someday
	- query-table:: false
	  #+BEGIN_QUERY
	  {:title [:h2 "Tasks"]
	   :query [:find (pull ?b [* {:block/_parent ...}])
	          :where
	          [?b :block/marker ?marker]
	          (not [?b :block/scheduled ?d])
	          (not [?b :block/deadline ?d])
	  (not (page-ref ?b "templates"))
	          [(contains? #{"TODO" "DOING"} ?marker)]]
	  }
	  #+END_QUERY