- # Midnight
- DONE commit journal
- [[勿說是推理/EP6]]
	- raika remained a mystery
	- she used code to communicate with kunou
	- four serial arson crime occurred in half a year
	- kunou met with a man, who seemed to be the accomplice of arsonist
	- kunou got set up, attacked by the man
- [[亂來!我居然會成為社長/EP6]]
	- asami turned down takahashi's kindness
	- takahashi's mother came to her house
	- her mother scold her for lack of planning
	- her mom met daiga, and took him home for dinner
	- her mom wanted she to marry him
	- takahashi's plan of opening 5 chain stores was hindered by nonaga
	- nonaga said he would crashed her company
	- takahashi had a quarrel with her mom
	- she thought of an idea about making their dishes into bento
	- her plan succeeded
- 04:18 #[[Bed Time]]
- # Morning
- 11:27 #[[Wake Time]]
- [[LeetCode Daily Challenge/2022-02]] #Array #Sorting
  id:: 621cbb98-d6c8-42c5-bda2-367641d65ec5
	- problem:: Remove Covered Intervals
	  link:: https://leetcode.com/problems/remove-covered-intervals/
	  difficulty:: Medium
	  duration:: 15mins
	- first time solving this problem
	- sort the array, then remove intervals by record current maximum right bound
- # Afternoon
- {{embed ((62106825-11bd-48e0-a78f-30c1a9a3c704))}}
-
- # Night
- {{embed ((62106825-11bd-48e0-a78f-30c1a9a3c704))}}
- [The System Design Primer](https://github.com/donnemartin/system-design-primer)
  id:: 6214e880-5415-4023-ac0e-2517b7ea28ab
	- type:: GitHub
	  tags:: [[System Design]], [[Job Interview]], [[Learning/Work]]
	  title:: The System Design Primer
	- {{youtube https://www.youtube.com/watch?v=-W9F__D3oY4}} ![lecture9.pdf](../assets/lecture9_1645382451788_0.pdf)
	  collapsed:: true
	  id:: 62125e07-cc66-400c-b183-a8d5a822fd25
		- type:: video
		  tags:: [[System Design]], [[Job Interview]], [[Learning/Work]], Scalability, [[Online Course]]
		  title:: CS75 (Summer 2012) Lecture 9 Scalability Harvard Web Development David Malan
		- type:: pdf
		  tags:: [[System Design]], [[Job Interview]], [[Learning/Work]], Scalability, [[Online Course]]
		  title:: Computer Science S-75 Building Dynamic Websites Lecture 9: Scalability
		- difference between shared web hosts and VPSs
			- shared web hosts may host your content along with others' on same machine
			- VPSs owner may divide a machine into several virtual machines with certain amount of resources, then sell those VM to customers
		- vertical scaling
			- add more resources to increase scalability
			- has technology barrier
		- horizontal scaling
			- add more machine, and design an architecture to solve the scalability problem
			- the load of each machine should be balanced
				- load balance distribute requests to each machine
				- machine connect to load balancer with private IP, and load balancer need to use DNS to let client know its public IP
			- machines can have different purpose, eg. content, computation or database, etc.
			- DNS with round robin can serve as a load balancer
				- suboptimal solution
				- bad luck
				- once the DNS record is cached on client side, the same machine will continue to be visited
			- user session problem
				- traditionally, session is saved on a local machine
				- a session one machine is not available to another machine
				- use one file server that connect to every other machine to store session
					- single point of failure
				- use RAID
					- redundant array of independent disks
				- sticky session
					- cookie cannot store all the information
					- cookie can store the id of the server last time visited
						- big random number
						- load balancer handle the cookie setting
		- caching
			- .html
				- serve static contents instead of dynamically generate one
				- redundancy to store all static files
				- unadaptable to changes
			- MYSQL
				- cache query result
			- memcached
				- memory cache
				- a server that store cache in RAM
				- add timestamp to each cache
		- data replication
			- master and slave databases
			- load balance queries
			- separate read and write query
				- write to master, then master writes to slaves
				- read from slaves
			- master-master architecture
				- two masters
				- write to one of the master
		- data partitioning
			- partition the data by certain rule, then store each group in one master-slaves cluster
	- performance vs scalability
	  collapsed:: true
		- a service is scalable if its performance can increase in proportional to resources add
			- better performance means handle more works in the same time, or be able to handle large work
		- having performance issue means the system is slow for a single user
		- having scalability issue means the system is slow under heavy load
		- [A Word on Scalability](https://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)
			- type:: article
			  tags:: [[System Design]], Scalability
			  title:: A Word on Scalability
			- an always-on service is said to be scalable if adding resources to facilitate redundancy does not result in a loss of performance
			- scalability cannot be after-thought, we need to design our system with scalability in mind
			- as system grows, heterogeneity may arise and algorithms that require uniformity may cost the system to break down or underutilize resources
				- heterogeneity means that some nodes will be able to process faster or store more data
		- [Scalability, Availability & Stability Patterns](https://www.slideshare.net/jboner/scalability-availability-stability-patterns/)
			- type:: slides
			  tags:: [[System Design]], Scalability, Availability, Stability
			  title:: Scalability, Availability & Stability Patterns
			- trade-offs
				- performance vs. scalability
					- performance problems occur when the system is slow for a single user
					- scalability problems occur when the system is fast for a single user but slow under heavy load
				- latency vs. throughput
					- a system should strive for maximum throughput with acceptable latency
				- availability vs. consistency
					- CAP theorem
						- we can only pick two of consistency, availability and partition tolerance
						- centralized systems choose availability and consistency
							- we don't need partition
							- ACID
							- atomic, consistent, isolated and durable
						- distributed systems can only choose one of availability and consistency
							- partition already exists in the network
							- CP and AP systems
			- availability patterns
				- fail-over
				- replication
					- master-slave replication
					- tree replication
					- master-master replication
					- buddy replication
			- scalability patterns
				- state
					- partitioning
					- HTTP caching
						- reverse proxy
						- CDN
						- precompute content
					- RDBMS sharding
					- NoSQL
						- types
							- key-value
							- column
							- reverse proxy
							- graph
							- data structure
						- eventual consistency
					- distributed caching
						- write through
						- write behind
						- eviction policies
						- replication
						- P2P
					- data grids
						- parallel data storages
					- concurrency
						- shared state
							- every time can access anything at anytime
							- indeterministic
						- message passing
							- asynchronous and non blocking
							- no shared state
						- dataflow
							- data driven
						- software transactional
				- behavior
					- event driven architecture
						- domain events
						- event sourcing
						- command and query responsibility segregation pattern
						- event stream processing
						- messaging
						- enterprise service bus
						- actors
						- enterprise integration architecture
					- compute grids
					- load balancing
					- parallel computing
			- stability patterns
				- timeouts
				- circuit breaker
				- let it crash
					- embrace failure in the life cycle
					- manage failure
				- fail fast
					- avoid slow responses
				- bulkheads
					- partition and tolerate failure in one part
				- steady state
				- throttling
					- maintain a steady pace
	- latency vs throughput
	  collapsed:: true
		- we should generally aim for maximal throughput with acceptable latency
		- [Understanding Latency versus Throughput](https://community.cadence.com/cadence_blogs_8/b/sd/posts/understanding-latency-vs-throughput)
		  collapsed:: true
			- type:: article
			  tags:: [[System Design]], Latency, Throughput
			  title:: Understanding Latency versus Throughput
			- latency is the time required to perform some action or to produce some result
			  collapsed:: true
				- measured in time unit
			- throughput is the number of such actions executed or results produces per unit of time
			  collapsed:: true
				- measured in units of whatever is being produced
	- availability vs consistency
	  collapsed:: true
		- [CAP Theorem: Revisited](https://robertgreiner.com/cap-theorem-revisited/)
		  collapsed:: true
			- type:: article
			  tags:: [[CAP Theorem]], [[System Design]], Availability, Consistency
			  title:: CAP Theorem: Revisited
			- CAP theorem: you can only get two of consistency, availability and partition tolerance
			  collapsed:: true
				- consistency
				  collapsed:: true
					- a read is guaranteed to return the most recent write for a given client
				- availability
				  collapsed:: true
					- a non-failing node will return a reasonable response within a reasonable amount of time
				- partition tolerance
				  collapsed:: true
					- the system will continue to function when network partitions occur
					- a network partition is a division of a computer network into relatively independent subnets
			- networks and parts of networks go down frequently and unexpectedly, so we must tolerate partition in distributed systems
			- CP
			  collapsed:: true
				- wait for a response from the partitioned node which could result in a timeout error
				- can also return an error
				- used in businesses require dictate atomic reads and writes
			- AP
			  collapsed:: true
				- return the most recent version of the data you have
					- could be outdated
				- accept writes that can be processed later when the partition is resolved
				- used in businesses that allow for some availability around when the data in the system synchronizes
	- consistency patterns
	  collapsed:: true
		- consistency means every read from the client will receive the most recent write or an error
		- weak consistency
		  collapsed:: true
			- best effort
			- after a write, reads may or may not see it
			- used in systems like memcached, video chat or online game
		- eventual consistency
		  collapsed:: true
			- data replication is asynchronous
			- after a write, reads will eventually see it
			- used in systems like DNS or email that require high availability
		- strong consistency
		  collapsed:: true
			- data replication is synchronous
			- after a write, reads will see it
			- used in systems like file system or RDBMS that have transaction feature
	- availability patterns
	  collapsed:: true
		- fail over
			- active passive
			  collapsed:: true
				- signals exchanged between active and passive server periodically
				- if the passive server cannot receive the signal, it takes active server's spot
				- the downtime is determined by whether the passive server is hot standby or cold standby
			- active active
			  collapsed:: true
				- loads are spread between both servers
			- disadvantage
			  collapsed:: true
				- add more hardware and additional complexity
				- potential data loss
		- replication
		  collapsed:: true
			- master slave
			- master master
		- availability are measured by uptime as percentage
		- whether two components are in sequence or in parallel affects system's availability
			- if they are in sequence, then overall availability decreases, otherwise, the overall availability increases
	- domain name system
	  collapsed:: true
		- DNS translates a domain name to an IP address
		- DNS is hierarchical
		- routers or ISP provides information about which DNS server for lookup
		- DNS results can be cached in lower level DNS server or browsers
		- types of DNS record
		  collapsed:: true
			- NS
				- DNS servers for a given domain
			- MX
				- mail server for a given domain
			- A
				- IP address for a given name
			- CNAME
				- another domain name or A record for a given name
		- DNS can route traffic with certain method
		  collapsed:: true
			- weighted round robin
			- latency based
			- geolocation based
		- disadvantages
		  collapsed:: true
			- accessing a DNS server create a delay
			- management is hard
			- when DNS is being attacked, users may not be able to access certain website
		- more resources
		  collapsed:: true
			- [DNS architecture](https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx)
			- [DNS articles](https://support.dnsimple.com/categories/dns/)
	- content delivery network
	  collapsed:: true
		- a globally distributed network of proxy servers
		- static files are served from CDN
		- CDN improves performance in two ways
		  collapsed:: true
			- users receive content from data centers close to them
			- original servers don't have to handle all the request
		- push CDN
		  collapsed:: true
			- original server takes full responsibility for providing content to CDN and rewriting the URL to the CDN
			- content is only uploaded to CDN when it is created or updated
			- you can control when content expires and when it is updated
			- works well with small traffic sites, because contents rarely need to be transfered
		- pull CDN
		  collapsed:: true
			- CDN grabs new content from original server when a resource is being requested for the first time
			- may result in slower response time for first request
			- TTL determines how long the content is cached
			- reduce storage space, but may create redundant traffic
			- works well with heavy traffic sites
		- disadvantages
		  collapsed:: true
			- cost could be significant depending on traffic
			- content might be stale when the content is updated at the original server, but TTL hasn't expire
			- requires change or URL to point to CDN
	- load balancer
	  collapsed:: true
		- load balancer distributes requests to different servers or databases to achieve
		  collapsed:: true
			- prevent requests from going to unhealthy servers
			- prevent overloading resources
			- eliminate single point of failure
			- SSL termination
				- decrypt incoming requests and encrypt server responses
			- session persistence
				- sticky cookie
		- load balancer can implemented with hardware or software
		- L4 load balancing
		  collapsed:: true
			- load balancer makes its decision bases on information at the transport layer
				- IP addresses and ports
			- perform works like a NAT
				- changing incoming and outgoing packet's IP address and port
			- requires less computation
			- reference
			  collapsed:: true
				- [What Is Layer 4 Load Balancing?](https://www.nginx.com/resources/glossary/layer-4-load-balancing/)
					- type:: article
					  tags:: [[System Design]], [[Load Balancer]], [[Computer Network]] 
					  title:: What Is Layer 4 Load Balancing?
		- L7 load balancing
		  collapsed:: true
			- load balancer makes its decision bases on information at the application layer
				- contents of the header, message and cookies
			- balancer terminate the traffic, then makes a decision after it reads the information, following by opening a connection to the server it decides
			- can also apply optimizations and change of content
			- CPU intensive
			- can be used in systems that have servers with different purposes
			  collapsed:: true
				- servers that tuned for certain requests, thus increase overall system performance
			- reference
			  collapsed:: true
				- [What Is Layer 7 Load Balancing?](https://www.nginx.com/resources/glossary/layer-7-load-balancing/)
					- type:: article
					  tags:: [[System Design]], [[Load Balancer]], [[Computer Network]] 
					  title:: What Is Layer 7 Load Balancing?
		- load balancers help achieve horizontal scaling
		- disadvantages
		  collapsed:: true
			- load balancer can be a potential bottleneck if resource isn't enough
			- increase system complexity
			- single load balancer is another potential single point of failure
	- reverse proxy
	  collapsed:: true
		- a server that provides unified interfaces to the public
		- hide information of the system, backlist IPs and limit number of connections per user to increase security
		- increase scalability while client can only see the reverse proxy
		- perform SSL termination by decrypting incoming requests and encrypting outgoing responses
		- compress server responses
		- cache server responses
		- serve static contents without reaching to the actual servers
		- difference between load balancer and reverse proxy
		  collapsed:: true
			- they are very much alike, but reverse proxy has the above merits even there is only one web server behind it
		- disadvantages
		  collapsed:: true
			- increase system complexity
			- may introduce single point of failure
		- reference
		  collapsed:: true
			- [What is a Reverse Proxy vs. Load Balancer?](https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/)
			  collapsed:: true
				- type:: article
				  tags:: [[System Design]], [[Reverse Proxy]], [[Load Balancer]] 
				  title:: What is a Reverse Proxy vs. Load Balancer?
	- application layer
	  collapsed:: true
		- also known as platform layer
		- application layer is where the business logic resides
		- adding more application servers doesn't necessary mean we need to add more web servers
			- add flexibility to the system
			- scale two layers more easily
		- microservices
			- a suite of independently deployable, small and modular services
			- each services communicates through well-defined mechanism
		- service discovery
			- a system that help services to find each other by registering information of the services
			- it also check service integrity through HTTP endpoint
		- disadvantages
			- adding an application layer needs different views of the system
			- microservices can add complexity to the system
		- reference
		  collapsed:: true
			- [Introduction to architecting systems for scale.](https://lethain.com/introduction-to-architecting-systems-for-scale/)
			  collapsed:: true
				- type:: article
				  tags:: [[System Design]], [[Application Layer]], [[Microservices]]
				  title:: Introduction to architecting systems for scale.
	- database
	  collapsed:: true
		- RDBMS
		  collapsed:: true
			- data is organized in tables
			- has transaction ACID properties
			  collapsed:: true
				- atomicity
				  collapsed:: true
					- transaction is all or nothing
				- consistency
				  collapsed:: true
					- a transaction will bring the database from one valid state to another
				- isolation
				  collapsed:: true
					- executing multiple transaction concurrently has the same results as if the transactions were executed serially
				- durability
				  collapsed:: true
					- the result of one transaction will remain in the database
			- scaling
			  collapsed:: true
				- master-slave replication
				  collapsed:: true
					- there is only one master in the system
					- master can serve read and write requests
					- slaves can only serve read requests
					- master will replicate writes into slaves, and a slave can replicate to other slaves in tree hierarchy
					- if the master go down, then the system can only serve read requests, until a slave is promoted to master
					- disadvantage
						- additional logic for promoting a slave to master
				- master-master replication
				  collapsed:: true
					- system has two masters
					- both masters serve read and write requests
					  collapsed:: true
						- one of them go down doesn't affect system's functionality
					- disadvantages
					  collapsed:: true
						- may need a load balancer or logic for application about which database to write
						- may violate ACID properties or lengthen write latency
						- conflict resolution may need to be execute frequently
				- disadvantages of replication
				  collapsed:: true
					- some data may lost before a new master is online
					- master may need to replicate to multiple slaves or another master, which increases its load
					- hardware complexity
				- federation
				  collapsed:: true
					- functional partitioning
					- splits database by function
					- with smaller database system, we can reduce replication lag
					- we can also improve cache locality
					- disadvantages
					  collapsed:: true
						- federation is not effective if the schema requires huge functions or tables
						- need to update application logic
						- joining data become more complex
						- hardware complexity
				- sharding
				  collapsed:: true
					- distribute data across different database
					- every database only manages a subset of the data
					- less request traffic and replication, more cache hits
					- reduce index size
					- no central master, so parallel writing is possible to increase throughput
					- disadvantages
						- need to update application logic
						- data distribution may be unbalanced
							- use [consistent hashing](http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html) to reduce the complexity
						- joining data become more complex
						- hardware complexity
					- reference
					  collapsed:: true
						- [An Unorthodox Approach To Database Design : The Coming Of The Shard](http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html)
						  collapsed:: true
							- type:: article
							  tags:: [[System Design]], Database, Sharding
							  title:: An Unorthodox Approach To Database Design : The Coming Of The Shard
				- denormalization
				  collapsed:: true
					- write redundant copies of data into multiple tables to avoid joins
					- improve read performance at the expense of some write performance
					- databases that adopt federation or sharding and also make use of this approach
					- weighing on the ratio of read and write requests
					- disadvantages
					  collapsed:: true
						- duplicated data
						- complex database design
						- may have subpar performance with heavy write requests
				- SQL tuning
				  collapsed:: true
					- benchmark and profile to find bottlenecks
					  collapsed:: true
						- benchmark simulate high-load situations
						- profile uses tools to track performance issue
					- tighten up the schema
					- use good indices
					- avoid expensive joins
					  collapsed:: true
						- denormalize the tables
					- partition tables
					  collapsed:: true
						- break up a table by putting hot spots in a separate table to help keep it in memory
					- tune the query cache
		- NoSQL
		  collapsed:: true
			- collection of data items represented in a key-value store, document store, wide column store or a graph store
			- data is denormalized
			- lack of ACID properties, favor eventual consistency
			- BASE
			  collapsed:: true
				- basically available
					- guarantee availability
				- soft state
					- the state of the system may change over time, even without input
				- eventual consistency
					- the system will become consistent over a period of time
			- key-value store
			  collapsed:: true
				- $O(1)$ reads and writes
				- used for simple data models or rapidly changing data
					- shift the complexity to application layer
				- basis for more complex systems
			- document store
			  collapsed:: true
				- centered around documents like XML, JSON or binary
				- provide APIs or query language to query documents
				- documents may have fields that are completely different from each other
				- used for occasionally changing data
			- wide column store
			  collapsed:: true
				- column as basic unit
				- column can be grouped in column families
				- used for very large data sets
			- graph database
			  collapsed:: true
				- each node is a record
				- each arc is a relationship
				- optimized to represent complex relationships
		- SQL or NoSQL
		  collapsed:: true
			- reasons for using SQL
			  collapsed:: true
				- structured data
				- strict schema
				- relational data
				- need for complex joins
				- transactions
				- clear patterns for scaling
				- lookup using index
				- more established community
			- reasons for using NoSQL
			  collapsed:: true
				- semi-structured data
				- flexible schema
				- non-relational data
				- no need for complex joins
				- huge data
				- data intensive workload
				- high throughput
			- reference
			  collapsed:: true
				- [SQL vs NoSQL: The Differences](https://www.sitepoint.com/sql-vs-nosql-differences/)
				  collapsed:: true
					- type:: article
					  tags:: [[System Design]], Database, SQL, NoSQL
					  title:: SQL vs NoSQL: The Differences
	- cache
	  collapsed:: true
		- caching improves response time and reduce server load
		- the dispatcher will first find if the cache exist, then execute the actual request
		- putting a cache in front of the database can absorb uneven loads
		- client caching
		  collapsed:: true
			- caches are located on the client OS or browser
		- CDN caching
		  collapsed:: true
			- CDN can be considered a type of cache
		- web server caching
		  collapsed:: true
			- reverse proxies can serve static and dynamic content directly
			- web servers can cache requests and respond directly without consulting the application servers
		- database caching
		  collapsed:: true
			- optimize database caching can boost performance
		- application caching
		  collapsed:: true
			- in memory caches such as Memcached and Redis are faster then database
			- need cache invalidation algorithms to remove cache from the memory
		- caching at the database query level
		  collapsed:: true
			- hash the query as the key, and the result as the value
			- hard to delete a cached result with complex queries
			- a small change in database may affect a lot of caches
		- caching at the object level
		  collapsed:: true
			- see data as an object
			- user sessions, web pages, activity streams, user graph data
		- when to update the cache
		  collapsed:: true
			- we need a cache update strategy because only have limited storage for cache
			- cache-aside
			  collapsed:: true
				- steps
				  collapsed:: true
					- application looks for entry in cache, resulting in a cache miss
					- read from database
					- add entry to cache
					- return entry
				- only requested data is cached
				- lazy loading
				- Memcached is used in this manner
				- disadvantages
				  collapsed:: true
					- may cause a noticeable delay
					- data in cache may become stale
						- use TTL to invalidate cache
					- when a node fails, there is no cache on the new node
			- write-through
			  collapsed:: true
				- steps
				  collapsed:: true
					- application adds or updates entry in cache
					- cache synchronously writes entry to data store
					- return
				- slow because of write operation
				- data in the cache is not stale
				- disadvantages
				  collapsed:: true
					- when a node fail, the new node will not cache entries until the entry is updated in the database
					- most data written might never be read
			- write-behind
			  collapsed:: true
				- steps
					- add or update entry in cache
					- asynchronously write entry to the data store
				- disadvantages
					- potential data loss if the cache goes down prior it writes its contents to data store
					- more complicated than cache-aside and write-through
			- refresh-ahead
			  collapsed:: true
				- configure the cache to automatically refresh any recently accessed cache entry prior to its expiration
				- reduce latency if the cache can predict accurately which items are likely to be requested in the future
				- disadvantages
				  collapsed:: true
					- will reduce performance if the cache failed to predict which items are likely to be needed in the future
		- disadvantages
		  collapsed:: true
			- need to maintain consistency between cache and database through cache invalidation
			- cache invalidation and when to update the cache are difficult problems
			- need to change application logic
	- asynchronism
	  collapsed:: true
		- asynchronous workflows reduce times for expensive operations
		- message queues
		  collapsed:: true
			- receive, hold and deliver messages
			- application and publish a job to a queue, then keep the user notified about the status
			- a worker can pick up a job in a queue, process it, then signal the job is completed
			- user is not blocked and jobs are processed in the background
		- task queues
		  collapsed:: true
			- task queues receive tasks and data, run them then deliver the results
			- can be used to run computation intensive jobs in the background
		- back pressure
		  collapsed:: true
			- back pressure help to maintain the queue in a reasonable size
			- clients cannot access the service once the queue fills up
		- disadvantages
		  collapsed:: true
			- not suitable for inexpensive or realtime operations
		- reference
		  collapsed:: true
			- [Applying Back Pressure When Overloaded](https://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html)
				- type:: article
				  tags:: [[System Design]], [[Message Queue]]
				  title:: Applying Back Pressure When Overloaded
	- communication
	  collapsed:: true
		- HTTP
		  collapsed:: true
			- an application protocol
			- a method for encoding and transporting data between a client and a server
			- request and response protocol
			- |  Verb | Description | Idempotent  | Safe  | Cacheable  |
			  |---|---|---|---|---|
			  |  GET | Read a resource  | Yes  | Yes  |  Yes |
			  |  POST | Create a resource or trigger a process that handle data  | No  | No  | Yes  |
			  |  PUT | Create or replace a resource  | Yes | No  | No |
			  | PATCH| Partially update a resource | No | No | Yes  |
			  | DELETE | Delete a resource | Yes | No| No|
		- TCP
		  collapsed:: true
			- connection oriented protocol
			- connection is established and terminated through handshake
			- all packets sent are guaranteed to reached the destination in order and without corruption
				- sequence numbers
				- checksum
				- ACK and retransmission
			- implements flow control and congestion control
				- less efficient than UDP
			- useful for application that require reliability but not time critical
			- connection pooling can help preventing applications from creating excessive TCP connections
		- UDP
		  collapsed:: true
			- connectionless
			- doesn't have congestion control
			- doesn't guarantee in order transmission
			- can be used to broadcast data to all the devices in a subnet
			- works well in real time application
		- RPC
		  collapsed:: true
			- client causes a procedure to execute on a different address space
			- abstract the details of how a client communicate with the server
			- steps
			  collapsed:: true
				- client calls the client stub procedure
					- the parameters are pushed onto the stack
				- client stub procedure marshals procedure ID and parameters into a request
				- client communication module sends the request to the server
				- server communication module passes the incoming requests to server stub procedure
				- server stub procedure unmarshalls the requests, calls server procedure that matches the procedure ID
				- server sends the response by repeating the steps above
			- disadvantages
			  collapsed:: true
				- hard to debug
				- clients become tightly coupled to the service implementation
				- a new API must be defined for every new operation
		- REST.
		  collapsed:: true
			- an architectural style
			- client acts on a set of resources managed by the server
			- server provides a representation of resources and actions on the resources
			- all communication must be stateless and cacheable
			- focuses on exposing data
			- identify resources, change with representations, self-descriptive error message, HTML interface for HTTP
			- disadvantages
			  collapsed:: true
				- not suitable for resources that are not naturally organized or accessed in a simple hierarchy
				- relies on a few verbs which sometimes doesn't fit the use case
				- fetching complicated resources with hierarchy requires multiple round trips
				- new fields may be added, older clients may receive redundant data
		- references
		  collapsed:: true
			- [When are RPC-ish approaches more appropriate than REST?](https://softwareengineering.stackexchange.com/questions/181176/when-are-rpc-ish-approaches-more-appropriate-than-rest/181186#181186)
			- [Do you really know why you prefer REST over RPC?](https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/)
			- [REST vs JSON-RPC?](https://stackoverflow.com/questions/15056878/rest-vs-json-rpc)
	- security
	  collapsed:: true
		- encrypt in transition and at rest
		- sanitize all user inputs or any input parameters exposed to user to prevent XSS and SQL injection
		- use parameterized queries to prevent SQL injection
		- use the principle of least privilege
		- reference
			- [API Security Checklist](https://github.com/shieldfy/API-Security-Checklist)
	-